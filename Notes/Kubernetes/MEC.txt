Content-Type: text/x-zim-wiki
Wiki-Format: zim 0.6
Creation-Date: 2023-08-08T15:42:00+01:00

====== MEC ======
Créée le Tuesday 08 August 2023

===== Installe traefik comme controler ingress =====

Utiliser helm en tant que root

__Installer HELM__ 
	''curl ''[[https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3|''https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3'']]'' | bash''

__Nous allons utiliser helm pour installer traefik comme ingress controller__
	''helm repo add traefik ''[[https://helm.traefik.io/traefik|''https://helm.traefik.io/traefik'']]

__Récuperer les valeurs par defaut__
	''helm show values traefik/traefik > traefik.yml''

__Ensuite modifier les valeurs par defaut__
	''vim traefik.yml''
	
````
service:
...
# Addresse IP des noeuds qui peuvent accepter des requetes de l'exterieur
  externalIPs:
	- X.X.X.X
globalArguments:
  # Désactive la verification ssl au niveau du backend
  - "--serversTransport.insecureSkipVerify=true"
  - "--entryPoints.web.proxyProtocol.insecure"
  - "--entryPoints.web.forwardedHeaders.insecure"

...
# Décommenteurs les clés Port
ports:
  traefik:
	Port: 9000
	expose: true
  web:
	Port: 80
  websecure:
	Port: 443
logs:
  # Traefik logs concern everything that happens to Traefik itself (startup, configuration, events, shutdown, and so on).
  general:
	level: DEBUG
  access:
	# To enable access logs
	enabled: true

```


__Activer le dashboard de traefik__
```
ingressRoute:
  dashboard:
	enabled: true
	# Additional ingressRoute annotations (e.g. for kubernetes.io/ingress.class)
	annotations: {}
	# Additional ingressRoute labels (e.g. for filtering IngressRoute by custom labels)
	labels: {}
	# The router match rule used for the dashboard ingressRoute
	matchRule:  Host(`lazok-traefik.lan`) &&  PathPrefix(`/dashboard`) || PathPrefix(`/api`)
	# Specify the allowed entrypoints to use for the dashboard ingress route, (e.g. traefik, web, websecure).
	# By default, it's using traefik entrypoint, which is not exposed.
	# /!\ Do not expose your dashboard without any protection over the internet /!\
	entryPoints: ["web"]
	# Additional ingressRoute middlewares (e.g. for authentication)
	middlewares: []
	# TLS options (e.g. secret containing certificate)
	tls: {}
```

__Ensuite installer__
''helm upgrade -n kube-system -i traefik traefik/traefik -f traefik.yml''
	

//si la ressource existe deja// 
	''kubectl delete ingressclasses traefik'' 









===== Configure des ingress pour pouvoir joindre tes pods =====

__Testons L'Ingress__

Attaquons notre application via un nom de domaine (myservicename.lan)
Pour tester le controller, creer un webservice de test

	''kubectl create deployment demo --image=httpd --port=80''

	''kubectl expose deployment demo''
# ou
	''kubectl create service clusterip demo --tcp=80:80''


__Ensuite créer une resource ingress__

'''
kubectl create ingress demo-web --class=traefik\
  --rule=demo.lan/*=demo:80
'''



Détails:

	''kubectl create ingress ingress-name --class=ingress_controller --rule=demo.lan/*=myservice-name:service-port''


//NB: --class=nginx si l'ingress controller c'est nginx et --class=traefik si l'ingress controller c'est traefik//



Testons

	''curl -H "Host:demo.lan" http://10.1.4.153/''

__Attaquons notre application via un endpoint (mydomain.lan/myservicename)__

Créons un deploy:

'''
kubectl create deploy webapp --image nginx
kubectl create service clusterip webapp --tcp=8080:80
'''


Créons un fichier manifest comme suit:

	''vim myingress.yml''

```
apiVersion: traefik.containo.us/v1alpha1
kind: Middleware
metadata:
  name: monitor
  namespace: default
spec:
  stripPrefix:
	forceSlash: false
	prefixes:
	  - /webapp
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
	ingress.kubernetes.io/rewrite-target: /
	kubernetes.io/ingress.class: traefik
	traefik.ingress.kubernetes.io/router.middlewares: default-monitor@kubernetescrd
  generation: 3
  name: webapp
  namespace: default
spec:
  rules:
  - host: myapp.lan
	http:
	  paths:
	  - backend:
		  service:
			name: webapp
			port:
			  number: 8080
		path: /webapp
		pathType: Prefix
status:
  loadBalancer: {}


```

kubectl apply -f myingress.yml

curl -H "Host:mydomain.lan" http://10.1.4.153/webapp


===== Installe rancher pour gerer le cluster =====

sudo docker run --privileged -d --restart=unless-stopped -p 80:80 -p 443:443 rancher/rancher




helm repo add jetstack https://charts.jetstack.io
helm repo add rancher-stable https://releases.rancher.com/server-charts/stable
helm repo update
helm install cert-manager jetstack/cert-manager  --namespace cert-manager  --create-namespace  --version v1.7.1 --set installCRDs=true
kubectl get pods --namespace cert-manager
helm upgrade -i rancher rancher-stable/rancher --create-namespace  --namespace cattle-system --version 2.7   --set bootstrapPassword=admin  --set hostname=rancher.smile.ci



===== Deploie grafana et prometheus depuis rancher pour le monitoring =====

{{~/Images/Captures d’écran/Capture d’écran du 2023-08-25 21-46-40.png}}





{{~/Images/Captures d’écran/Capture d’écran du 2023-08-25 21-47-18.png}}
{{~/Images/Captures d’écran/Capture d’écran du 2023-08-25 21-48-35.png}}


installer __Monitoring__




===== Faut etudier comment faire la backup de ton cluster aussi =====

Il n’est pas rare que les utilisateurs d’offres Kubernetes gérées n’aient pas accès à la base de données etcd sous-jacente, ce qui rend les sauvegardes et restaurations directes pratiquement impossibles et les oblige à utiliser diverses solutions de contournement.

https://fr.linux-console.net/?p=6564#gsc.tab=0

https://devopssec.fr/article/sauvegarder-restaurer-cluster-kubernetes









cephadm bootstrap  --mon-ip 192.168.1.242   --allow-fqdn-hostname

ceph 
https://kube-master.dev01.smile.lan:8443    


ceph orch host add kube-node.dev01.smile.lan 192.168.1.246 --labels _admin




ceph orch device ls --wide --refresh
ceph orch daemon add osd kube-node.dev01.smile.lan :_DEVICE_PATH_









===== Pour désinstaller K3s serveur =====
Arrêter K3s :
	sudo systemctl stop k3s
Désinstaller K3s :
	sudo [[/usr/local/bin/k3s-uninstall.sh]]
	

===== Pour désinstaller K3s worker =====
	sudo [[/usr/local/bin/k3s-agent-uninstall.sh]]




https://docs.k3s.io/advanced



firewall-cmd --add-port=9000/tcp --permanent
sudo firewall-cmd  --remove-port=9000/tcp --permanent







export  K3S_URL=https://192.168.1.207:6443 
export K3S_TOKEN=K10c8c990fa815fbea6debeff73167b9f5f1a4761352905509c036764a9fc4e6f40::server:bf4320f2b2dacef70e5f9db1e9cd0d61
curl -sfL https://get.k3s.io | sh -s - --docker







velero install \
	--provider aws \
	--plugins velero/velero-plugin-for-aws:v1.5.0 \
	--bucket velero \
	--use-restic \
	--secret-file ./credentials-velero \
	--use-volume-snapshots=false \
	--backup-location-config region=default,s3ForcePathStyle="true",s3Url=http://10.1.4.153:<RGW_PORT> \
	--wait











'''
kubectl create ingress grafana --class=traefik\
  --rule=graf.kub/*=graf:80
'''











































cephadm bootstrap  --mon-ip *<mon-ip>*   --allow-fqdn-hostname









https://fr.linux-console.net/?p=6564#gsc.tab=0
https://docs.trilio.io/kubernetes/appendix/csi-drivers/installing-volumesnapshot-crds



















